{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7922020",
   "metadata": {},
   "source": [
    "# Práctica de Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e3eaf2",
   "metadata": {},
   "source": [
    "Con la práctica *Scraping* obtenemos de forma automática el contenido de una páginas web a través de su código HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17cbe0b",
   "metadata": {},
   "source": [
    "## Pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4937dbb6",
   "metadata": {},
   "source": [
    "Para realizar esta técnica son necesarios tres pasos básicos\n",
    "\n",
    "**1. Elegir la URL de la página**\n",
    "\n",
    "**2. Estudiar la estructura de la página**\n",
    "\n",
    "**3. Obtener los datos y tratarlos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176005b4",
   "metadata": {},
   "source": [
    "### Elegir la URL de la página"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80afac5",
   "metadata": {},
   "source": [
    "Para ello primero será necesario interactuar con la URL elegida a través de librerías que\n",
    "nos permitan cargar páginas web. Estas son `requests`y `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa6935",
   "metadata": {},
   "source": [
    "### Importamos estas librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56beea0",
   "metadata": {},
   "source": [
    "Con la librería [requests](https://docs.python-requests.org/en/latest/) descargamos el contenido de la página El contenido de la respuesta, el que contiene la página en HTML, será el que pasemos posteriormente a `BeautifulSoup`para generar el árbol de elementos y poder hacer consultas al mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75787016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05afd59",
   "metadata": {},
   "source": [
    "Después importamos la librería [bs4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) `BeautifulSoup` El contenido de la página obtenido en el paso anterior será el que utilicemos para crear la «sopa», esto es, el árbol de objetos *Python* que representan al documento *HTML*.\n",
    "\n",
    "Para ello, hay que crear un objeto de tipo `BeautifulSoup`, al cual pasamos el texto en formato *HTML* y el identificador del *parser* a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c80c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de5778",
   "metadata": {},
   "source": [
    "### Definimos URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6895ae3e",
   "metadata": {},
   "source": [
    "En este caso la URL pertenece a el periódico El País = \"https://resultados.elpais.com/deportivos/juegos-olimpicos/medallero/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7144e",
   "metadata": {},
   "source": [
    "Es importante que comprobemos primero que podemos acceder a estos datos, para ello primero preguntamos hacemos la consulta. Si los accesos nos devuelven `HTTP 200 Ok`, la respuesta es\n",
    " correcta. Si no, lanzamos la excepción de que no podemos acceder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7924df38",
   "metadata": {},
   "source": [
    "### Realizamos la petición a la web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c47966",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_23384/3563584904.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\MIRIAN~1.TUR\\AppData\\Local\\Temp/ipykernel_23384/3563584904.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Si el estatus code no es `200` no se puede leer la página\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Si el estatus code no es `200` no se puede leer la página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(URL)\n",
    "if (req.status_code != 200):\n",
    "    raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "if (req.status_code == 200):\n",
    "    print(\"Vamos a por ello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ffd6bf",
   "metadata": {},
   "source": [
    "### De requests a Beautiful Soupe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3af8788",
   "metadata": {},
   "source": [
    "Como hemos mencionado antes tenemos que crear un objeto de tipo `BeautifulSoup()` al cual pasamos el texto en formato *HTML* y el identificador del parser a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46844331",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = BeautifulSoup(req.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a2385e",
   "metadata": {},
   "source": [
    "###  Variables de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4621b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Es necesario estudiar la estructura *HTML* de la página para poder obtener los datos, que es el\n",
    "objetivo del *Web Scraping*. Para ello debemos conocer la estructura de la página y una vez conocida,\n",
    "a través de la librería de `BeautifulSoup` podremos ir obteniendo las diferentes estructuras HTML que\n",
    "hay en ellas y recolectando los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9045c2a3",
   "metadata": {},
   "source": [
    "Definimos las variables `paises`, `oros`, etc y las identificamos con la función `find_all()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e395fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "  paises = html.find_all(\"th\",{\"class\":\"pais\"})\n",
    "  oros = html.find_all(\"td\",{\"class\":\"m_oro\"})\n",
    "  platas = html.find_all(\"td\",{\"class\":\"m_plata\"})\n",
    "  bronces = html.find_all(\"td\",{\"class\":\"m_bronce\"})\n",
    "  totales = html.find_all(\"td\",{\"class\":\"m_total\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9733d1",
   "metadata": {},
   "source": [
    "Como se puede observar, con `find_all` obtendremos los trozos de código necesario para\n",
    "obtener los datos. Con estas funciones podemos ir obteniendo los elementos que nos interesan para\n",
    "obtener los datos que tienen y poder tratarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a0ed85",
   "metadata": {},
   "source": [
    "### Hacemos la pregunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c09816",
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta=input('¿QUIERES CONOCER LOS 20 PAÍSES QUE HAN OBTENIDO MÁS MEDALLAS EN 2020?\\n \\n Si tu respuesta es Sí, presiona \"s\" \\n')\n",
    "if(respuesta == 's'):\n",
    "    print('Vale, vamos a ello')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf446d0",
   "metadata": {},
   "source": [
    "### Bucle para obtener los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6807d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Creamos un bucle con `for`y `else`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49f3370",
   "metadata": {},
   "outputs": [],
   "source": [
    " print('\\nRESULTADOS DE LOS DATOS DE LOS JUEGOS OLÍMPICOS 2020\\n')\n",
    "  print ('PAÍSES')\n",
    "  for i in range (20):\n",
    "    # Con el método \"getText()\" no nos devuelve el HTML\n",
    "    print(\"%d. %s \\nOro: %s Plata: %s Bronce: %s \\n Total: %s \\n \" % (i+1, paises[i+1].text.strip(),oros[i].text.strip(),platas[i].text.strip(),bronces[i].text.strip(), totales[i].text.strip()))\n",
    "else:\n",
    "  print('Qué lástima, y...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99292232",
   "metadata": {},
   "source": [
    "Código fuente en [bruto](https://github.com/nebrijas/periodismodedatos-MiramBT16/blob/main/ad2.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8a36cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
